{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2560f3e8-0e7d-4c0a-bf1f-9bf493de3ace",
   "metadata": {},
   "source": [
    "# Feature Engineering and Modeling\n",
    "\n",
    "In this notebook, I will build upon the preprocessed dataset created in the `01_data_loading_and_exploration.ipynb` notebook. Here, I will:\n",
    "\n",
    "1. Possibly perform additional feature engineering (if needed) to improve predictive performance.\n",
    "2. Train a baseline machine learning model (e.g., Logistic Regression) to establish a performance benchmark.\n",
    "3. Evaluate the model using appropriate metrics.\n",
    "4. Potentially experiment with more advanced models or parameter tuning.\n",
    "\n",
    "By the end of this notebook, I should have a good sense of how well a simple model can predict credit risk and understand where there might be room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d925f54f-936f-4a24-ae22-a7d81c5e3a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (800, 48)\n",
      "X_test shape: (200, 48)\n",
      "y_train shape: (800,)\n",
      "y_test shape: (200,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load the previously saved train_test splits\n",
    "X_train = joblib.load(\"../data/X_train.pkl\")\n",
    "X_test = joblib.load(\"../data/X_test.pkl\")\n",
    "y_train = joblib.load(\"../data/y_train.pkl\")\n",
    "y_test = joblib.load(\"../data/y_test.pkl\")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b6e8b-49f1-4130-a64a-64d7b23c934e",
   "metadata": {},
   "source": [
    "### Baseline Model: Logistic Regression\n",
    "\n",
    "Before diving into complex models or extensive parameter tuning, I will start with a simple baseline model. Logistic Regression is a classic linear model often used as a first benchmark in classification tasks. \n",
    "\n",
    "**Why Logistic Regression?**  \n",
    "- It’s straightforward and widely understood, making it an excellent first choice to gauge the difficulty of the prediction problem.\n",
    "- It runs quickly and gives a point of comparison for more advanced models later.\n",
    "- If Logistic Regression performs reasonably well, it suggests that linear relationships between features and the target are informative. If it performs poorly, it may indicate that more complex relationships or features are needed.\n",
    "\n",
    "**What Am I Looking For?**  \n",
    "- **Accuracy**: How many predictions are correct overall.\n",
    "- **Precision/Recall/F1-score**: To understand the quality of predictions for each class, especially the \"bad\" credit class, which might be more critical to identify accurately.\n",
    "- **Confusion Matrix**: To see if the model predominantly misclassifies one class over the other.\n",
    "\n",
    "After evaluating Logistic Regression, I’ll know whether I need more advanced techniques (e.g., Random Forests, Gradient Boosted Trees) or additional data transformations. This baseline sets the foundation for all subsequent improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cafeecb2-7eca-470a-a093-05916601b3dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SebastianGM\\anaconda3\\envs\\pd_model_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Initialize a Logistic Regression model with default parameters\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4b0ec3-57c7-4482-8274-e1c88ca2743b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.795\n",
      "\n",
      "Confusion Matrix:\n",
      " [[127  14]\n",
      " [ 27  32]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       141\n",
      "           1       0.70      0.54      0.61        59\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.76      0.72      0.74       200\n",
      "weighted avg       0.79      0.80      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca13be0-217f-4b05-a2a0-34bd69698b30",
   "metadata": {},
   "source": [
    "### Addressing the Convergence Warning\n",
    "\n",
    "I received a `ConvergenceWarning` which indicates that the Logistic Regression model did not fully converge within the given number of iterations (`max_iter=1000`). This can happen when:\n",
    "\n",
    "- Features are on different scales, making it harder for the optimizer to find a stable solution.\n",
    "- The default solver and iteration limit are insufficient for this particular dataset.\n",
    "\n",
    "**Why does scaling help?**  \n",
    "When features vary widely in scale (e.g., some in the hundreds, others less than one), the optimization algorithm struggles to navigate the feature space efficiently. By scaling all features to a similar range (for example, using StandardScaler to give them all a mean of 0 and a standard deviation of 1), the model can converge more easily.\n",
    "\n",
    "**Why increase `max_iter` or change the solver?**  \n",
    "If the optimizer doesn’t converge within the default number of iterations, giving it more iterations (`max_iter`) can help. Also, some solvers (like `liblinear`) may handle certain datasets more gracefully, converging faster or more reliably.\n",
    "\n",
    "**Next Step**: I will scale the data, increase `max_iter`, and use a different solver (`liblinear`) to see if the warning disappears and to ensure the model is properly converged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d3a9b7-a384-4839-b223-a4367de13c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Improved): 0.795\n",
      "\n",
      "Confusion Matrix (Improved):\n",
      " [[124  17]\n",
      " [ 24  35]]\n",
      "\n",
      "Classification Report (Improved):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.88      0.86       141\n",
      "           1       0.67      0.59      0.63        59\n",
      "\n",
      "    accuracy                           0.80       200\n",
      "   macro avg       0.76      0.74      0.74       200\n",
      "weighted avg       0.79      0.80      0.79       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize Logistic Regression with more iterations and a different solver\n",
    "model_improved = LogisticRegression(max_iter=2000, solver='liblinear', random_state=42)\n",
    "model_improved.fit(X_train_scaled, y_train)\n",
    "y_pred_improved = model_improved.predict(X_test_scaled)\n",
    "\n",
    "acc_improved = accuracy_score(y_test, y_pred_improved)\n",
    "cm_improved = confusion_matrix(y_test, y_pred_improved)\n",
    "report_improved = classification_report(y_test, y_pred_improved)\n",
    "\n",
    "print(\"Accuracy (Improved):\", acc_improved)\n",
    "print(\"\\nConfusion Matrix (Improved):\\n\", cm_improved)\n",
    "print(\"\\nClassification Report (Improved):\\n\", report_improved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc9f88b-6e9e-466a-9fe2-c814934a6212",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "By scaling the features and increasing the number of iterations, as well as selecting the `liblinear` solver, the Logistic Regression model now converges without warnings. This small adjustment demonstrates my ability to diagnose and fix common modeling issues.\n",
    "\n",
    "The performance might be similar or slightly different, but importantly, the model is now properly optimized. This sets a more solid baseline for comparison if I try more advanced models or further tune the pipeline in subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ac937b-e778-461f-9c59-a642f5a51060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64340809-b5c0-49c4-ace7-64f6d9806c97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PD Credit Env",
   "language": "python",
   "name": "pd_model_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
