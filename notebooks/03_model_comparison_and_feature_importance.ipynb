{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf8aa0d-7abb-42c6-8cfd-2412458b7ece",
   "metadata": {},
   "source": [
    "# Model Comparison and Feature Importance\n",
    "\n",
    "In this notebook, I will:\n",
    "1. Compare multiple machine learning algorithms beyond Logistic Regression, such as Random Forest and XGBoost, to see if I can improve predictive performance.\n",
    "2. Implement basic hyperparameter tuning using GridSearchCV or RandomizedSearchCV to optimize model settings.\n",
    "3. Evaluate models using metrics that are crucial for credit risk analysis, such as AUC-ROC and Precision-Recall curves, since identifying \"bad\" credit risks is more important than overall accuracy.\n",
    "4. Explore feature importance and model interpretability. Understanding which features drive the model’s decisions is vital in a credit risk context, where explainability is often a regulatory and business requirement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c5d5cac-4036-4c3b-bc3e-fb475bcfb1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, RocCurveDisplay, PrecisionRecallDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the data\n",
    "X_train = joblib.load(\"../data/X_train.pkl\")\n",
    "X_test = joblib.load(\"../data/X_test.pkl\")\n",
    "y_train = joblib.load(\"../data/y_train.pkl\")\n",
    "y_test = joblib.load(\"../data/y_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372d36f6-8e4b-4d07-9902-08642d67e070",
   "metadata": {},
   "source": [
    "### Random Forest Baseline\n",
    "\n",
    "I'll train a basic Random Forest with default parameters and compare its performance to the Logistic Regression baseline. Random Forests are often good at handling complex interactions between features and may provide better recall for the \"bad\" class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634a00aa-6a52-43dc-9507-7241bfc85764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.745\n",
      "Random Forest AUC: 0.7909604519774011\n",
      "\n",
      "Classificaction Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.83       141\n",
      "           1       0.62      0.34      0.44        59\n",
      "\n",
      "    accuracy                           0.74       200\n",
      "   macro avg       0.70      0.63      0.64       200\n",
      "weighted avg       0.73      0.74      0.72       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "auc_rf = roc_auc_score(y_test, rf.predict_proba(X_test)[:,1]) # Calculate AUC\n",
    "print(\"Random Forest Accuracy:\", acc_rf)\n",
    "print(\"Random Forest AUC:\", auc_rf)\n",
    "\n",
    "print(\"\\nClassificaction Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4152a1ce-0127-48d2-94a7-c4890c196a8d",
   "metadata": {},
   "source": [
    "The Random Forest's accuracy and AUC provide a quick snapshot. If the AUC is higher than Logistic Regression’s AUC, it suggests the Random Forest may be better at ranking which customers are more likely to be bad credit risks. I will pay special attention to the recall for the bad class and the AUC-ROC, as these metrics align better with credit risk priorities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d33728e-aaa1-4db2-9f0b-7e661e7261e8",
   "metadata": {},
   "source": [
    "#### Model Interpretation\n",
    "\n",
    "**Random Forest (Baseline):**  \n",
    "- **Accuracy:** 0.745  \n",
    "- **AUC:** 0.79  \n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "The baseline Random Forest model gives the following results:\n",
    "\n",
    "- **Accuracy (74.5%)**: Slightly lower than the Logistic Regression models, suggesting it is less effective at overall classification.\n",
    "- **Class 0 (Good Credit)**:\n",
    "  - **Recall (0.91)**: Very high, indicating the model identifies most good credit customers correctly.\n",
    "  - **Precision (0.77)**: Slightly lower than Logistic Regression.\n",
    "- **Class 1 (Bad Credit)**:\n",
    "  - **Recall (0.34)**: Much lower than Logistic Regression, meaning the model misses most bad credit customers.\n",
    "  - **Precision (0.62)**: Lower than Logistic Regression, indicating it is less reliable when predicting bad credit.\n",
    "\n",
    "**Key Takeaways:**\n",
    "While the Random Forest model excels at identifying good credit customers, its recall for the bad credit class is significantly worse than Logistic Regression, which makes it less suitable for a credit risk context without further tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb39d159-fc2f-481d-b255-a2a9f7cbdccb",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Random Forest\n",
    "\n",
    "I will use GridSearchCV to search for optimal hyperparameters for the Random Forest. This process demonstrates how I can improve the model further. I'll tune parameters like `n_estimators`, `max_depth`, and `min_samples_leaf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a4d8289-6294-4ede-b845-7cea662d9d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'max_depth': 10, 'min_samples_leaf': 5, 'n_estimators': 100}\n",
      "Best Score (AUC): 0.7623129915833197\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100,300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator = RandomForestClassifier(random_state=42),\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'roc_auc', # Using AUC as the scoring metric\n",
    "    cv = 3,\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"Best Score (AUC):\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca97333-4325-46c1-a992-aa47f23164b7",
   "metadata": {},
   "source": [
    "**Interpreting the Grid Search Results:**\n",
    "\n",
    "- `n_estimators`: Number of trees in the forest. More trees can improve performance but increase training time.\n",
    "- `max_depth`: Maximum depth of the trees. Deeper trees can model complex relationships but may overfit.\n",
    "- `min_samples_leaf`: Minimum samples per leaf. Increasing this can reduce overfitting.\n",
    "\n",
    "The best parameters are those that give the highest AUC on the validation folds. With these parameters, I'll retrain the model and evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af84e6aa-656d-4fe0-8f92-1640f4fd51d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Random Forest Accuracy: 0.75\n",
      "Optimized Random Forest AUC: 0.8015386464719317\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84       141\n",
      "           1       0.71      0.25      0.38        59\n",
      "\n",
      "    accuracy                           0.75       200\n",
      "   macro avg       0.73      0.61      0.61       200\n",
      "weighted avg       0.74      0.75      0.71       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_rf = grid_search.best_estimator_ \n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "\n",
    "acc_best_rf = accuracy_score(y_test, y_pred_best_rf)\n",
    "auc_best_rf = roc_auc_score(y_test, best_rf.predict_proba(X_test)[:,1])\n",
    "\n",
    "print(\"Optimized Random Forest Accuracy:\", acc_best_rf)\n",
    "print(\"Optimized Random Forest AUC:\", auc_best_rf)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_best_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfabe7d-c492-4d7a-8c87-5e8057ef0fae",
   "metadata": {},
   "source": [
    "#### Model Interpretation\n",
    "\n",
    "**Random Forest (Optimized):**  \n",
    "- **Accuracy:** 0.75  \n",
    "- **AUC:** 0.80154  \n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "After tuning the Random Forest with GridSearchCV, the model's performance is as follows:\n",
    "\n",
    "- **Accuracy (75%)**: Slight improvement over the baseline Random Forest.\n",
    "- **Class 0 (Good Credit)**:\n",
    "  - **Recall (0.96)**: Increased significantly, making it very effective at identifying good credit customers.\n",
    "  - **Precision (0.75)**: Similar to the baseline model.\n",
    "- **Class 1 (Bad Credit)**:\n",
    "  - **Recall (0.25)**: Decreased from the baseline Random Forest, which is concerning.\n",
    "  - **Precision (0.71)**: Improved slightly.\n",
    "\n",
    "**Key Takeaways:**\n",
    "While the optimized Random Forest improves overall metrics like accuracy and AUC, its recall for the bad credit class drops even further, making it less effective for practical use in credit risk management."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a5fcd9-f1f9-4ea0-9195-5a127ec47881",
   "metadata": {},
   "source": [
    "### Trying XGBoost\n",
    "\n",
    "XGBoost often performs well in tabular data tasks. I'll train a basic XGBoost classifier and see if it outperforms Random Forest. If it does well, I could also consider tuning its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e53c85e5-8bb7-41e5-807b-353950404536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.785\n",
      "XGBoost AUC: 0.8139199423007573\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.89      0.85       141\n",
      "           1       0.67      0.53      0.59        59\n",
      "\n",
      "    accuracy                           0.79       200\n",
      "   macro avg       0.75      0.71      0.72       200\n",
      "weighted avg       0.78      0.79      0.78       200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SebastianGM\\anaconda3\\envs\\pd_model_env\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [06:30:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0c55ff5f71b100e98-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "auc_xgb = roc_auc_score(y_test, xgb.predict_proba(X_test)[:,1])\n",
    "\n",
    "print(\"XGBoost Accuracy:\", acc_xgb)\n",
    "print(\"XGBoost AUC:\", auc_xgb)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd966c3d-f47d-4b2c-b778-49cb90c80eec",
   "metadata": {},
   "source": [
    "#### Model Interpretation\n",
    "\n",
    "**XGBoost:**  \n",
    "- **Accuracy:** 0.785  \n",
    "- **AUC:** 0.81392  \n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "XGBoost delivers the following results:\n",
    "\n",
    "- **Accuracy (78.5%)**: Higher than both Logistic Regression and Random Forest models.\n",
    "- **Class 0 (Good Credit)**:\n",
    "  - **Recall (0.89)**: Slightly lower than the optimized Random Forest but still strong.\n",
    "  - **Precision (0.82)**: Better than Random Forest.\n",
    "- **Class 1 (Bad Credit)**:\n",
    "  - **Recall (0.53)**: A significant improvement over both Random Forest models, on par with the improved Logistic Regression.\n",
    "  - **Precision (0.67)**: Matches the improved Logistic Regression.\n",
    "\n",
    "**Key Takeaways:**\n",
    "XGBoost offers a good balance between overall performance and recall for the bad credit class. Its ability to identify more bad credit customers compared to Random Forest makes it a strong candidate for credit risk modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1dc1f9-bbe9-4907-a84b-553e21489347",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfff55c-7d8b-4fd7-8797-74a4b8e2f11d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PD Credit Env",
   "language": "python",
   "name": "pd_model_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
